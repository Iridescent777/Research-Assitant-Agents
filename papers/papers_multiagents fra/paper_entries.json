[
    {
        "entry": {
            "Name": {
                "title": [
                    {
                        "text": {
                            "content": "Survey on Multi-Agent Q-Learning frameworks for resource management in wireless sensor network"
                        }
                    }
                ]
            },
            "Date": {
                "date": {
                    "start": "2021-05-05"
                }
            },
            "Authors": {
                "rich_text": [
                    {
                        "text": {
                            "content": "Arvin Tashakori"
                        }
                    }
                ]
            },
            "Abstract": {
                "rich_text": [
                    {
                        "text": {
                            "content": "This report aims to survey multi-agent Q-Learning algorithms, analyze\ndifferent game theory frameworks used, address each framework's applications,\nand report challenges and future directions. The target application for this\nstudy is resource management in the wireless sensor network.\n  In the first section, the author provided an introduction regarding the\napplications of wireless sensor networks. After that, the author presented a\nsummary of the Q-Learning algorithm, a well-known classic solution for\nmodel-free reinforcement learning problems.\n  In the third section, the author extended the Q-Learning algorithm for\nmulti-agent scenarios and discussed its challenges.\n  In the fourth section, the author surveyed sets of game-theoretic frameworks\nthat researchers used to address this problem for resource allocation and task\nscheduling in the wireless sensor networks. Lastly, the author mentioned some\ninteresting open challenges in this domain."
                        }
                    }
                ]
            },
            "Tags": {
                "multi_select": [
                    {
                        "name": "agent learning"
                    },
                    {
                        "name": "reinforcement learning"
                    },
                    {
                        "name": "multi agent"
                    },
                    {
                        "name": "sensor networks"
                    },
                    {
                        "name": "game theory"
                    }
                ]
            },
            "Github": {
                "url": null
            }
        },
        "pdf_path": "D:\\PJLAB\\Agent\\final_project\\papers\\papers_multiagents fra\\2105.02371v1.pdf",
        "arxiv_id": "2105.02371v1"
    },
    {
        "entry": {
            "Name": {
                "title": [
                    {
                        "text": {
                            "content": "Deep Multiagent Reinforcement Learning: Challenges and Directions"
                        }
                    }
                ]
            },
            "Date": {
                "date": {
                    "start": "2021-06-29"
                }
            },
            "Authors": {
                "rich_text": [
                    {
                        "text": {
                            "content": "Annie Wong, Thomas B\u00e4ck, Anna V. Kononova, Aske Plaat"
                        }
                    }
                ]
            },
            "Abstract": {
                "rich_text": [
                    {
                        "text": {
                            "content": "This paper surveys the field of deep multiagent reinforcement learning. The\ncombination of deep neural networks with reinforcement learning has gained\nincreased traction in recent years and is slowly shifting the focus from\nsingle-agent to multiagent environments. Dealing with multiple agents is\ninherently more complex as (a) the future rewards depend on multiple players'\njoint actions and (b) the computational complexity increases. We present the\nmost common multiagent problem representations and their main challenges, and\nidentify five research areas that address one or more of these challenges:\ncentralised training and decentralised execution, opponent modelling,\ncommunication, efficient coordination, and reward shaping. We find that many\ncomputational studies rely on unrealistic assumptions or are not generalisable\nto other settings; they struggle to overcome the curse of dimensionality or\nnonstationarity. Approaches from psychology and sociology capture promising\nrelevant behaviours, such as communication and coordination, to help agents\nachieve better performance in multiagent settings. We suggest that, for\nmultiagent reinforcement learning to be successful, future research should\naddress these challenges with an interdisciplinary approach to open up new\npossibilities in multiagent reinforcement learning."
                        }
                    }
                ]
            },
            "Tags": {
                "multi_select": [
                    {
                        "name": "multiagent reinforcement"
                    },
                    {
                        "name": "deep multiagent"
                    },
                    {
                        "name": "multiagent"
                    },
                    {
                        "name": "multiple agents"
                    },
                    {
                        "name": "to multiagent"
                    }
                ]
            },
            "Github": {
                "url": null
            }
        },
        "pdf_path": "D:\\PJLAB\\Agent\\final_project\\papers\\papers_multiagents fra\\2106.15691v2.pdf",
        "arxiv_id": "2106.15691v2"
    },
    {
        "entry": {
            "Name": {
                "title": [
                    {
                        "text": {
                            "content": "Self-Adaptive Large Language Model (LLM)-Based Multiagent Systems"
                        }
                    }
                ]
            },
            "Date": {
                "date": {
                    "start": "2023-07-12"
                }
            },
            "Authors": {
                "rich_text": [
                    {
                        "text": {
                            "content": "Nathalia Nascimento, Paulo Alencar, Donald Cowan"
                        }
                    }
                ]
            },
            "Abstract": {
                "rich_text": [
                    {
                        "text": {
                            "content": "In autonomic computing, self-adaptation has been proposed as a fundamental\nparadigm to manage the complexity of multiagent systems (MASs). This achieved\nby extending a system with support to monitor and adapt itself to achieve\nspecific concerns of interest. Communication in these systems is key given that\nin scenarios involving agent interaction, it enhances cooperation and reduces\ncoordination challenges by enabling direct, clear information exchange.\nHowever, improving the expressiveness of the interaction communication with\nMASs is not without challenges. In this sense, the interplay between\nself-adaptive systems and effective communication is crucial for future MAS\nadvancements. In this paper, we propose the integration of large language\nmodels (LLMs) such as GPT-based technologies into multiagent systems. We anchor\nour methodology on the MAPE-K model, which is renowned for its robust support\nin monitoring, analyzing, planning, and executing system adaptations in\nresponse to dynamic environments. We also present a practical illustration of\nthe proposed approach, in which we implement and assess a basic MAS-based\napplication. The approach significantly advances the state-of-the-art of\nself-adaptive systems by proposing a new paradigm for MAS self-adaptation of\nautonomous systems based on LLM capabilities."
                        }
                    }
                ]
            },
            "Tags": {
                "multi_select": [
                    {
                        "name": "autonomic computing"
                    },
                    {
                        "name": "multiagent systems"
                    },
                    {
                        "name": "self adaptive"
                    },
                    {
                        "name": "adaptive systems"
                    },
                    {
                        "name": "agent interaction"
                    }
                ]
            },
            "Github": {
                "url": null
            }
        },
        "pdf_path": "D:\\PJLAB\\Agent\\final_project\\papers\\papers_multiagents fra\\2307.06187v1.pdf",
        "arxiv_id": "2307.06187v1"
    },
    {
        "entry": {
            "Name": {
                "title": [
                    {
                        "text": {
                            "content": "GPT-in-the-Loop: Adaptive Decision-Making for Multiagent Systems"
                        }
                    }
                ]
            },
            "Date": {
                "date": {
                    "start": "2023-08-21"
                }
            },
            "Authors": {
                "rich_text": [
                    {
                        "text": {
                            "content": "Nathalia Nascimento, Paulo Alencar, Donald Cowan"
                        }
                    }
                ]
            },
            "Abstract": {
                "rich_text": [
                    {
                        "text": {
                            "content": "This paper introduces the \"GPT-in-the-loop\" approach, a novel method\ncombining the advanced reasoning capabilities of Large Language Models (LLMs)\nlike Generative Pre-trained Transformers (GPT) with multiagent (MAS) systems.\nVenturing beyond traditional adaptive approaches that generally require long\ntraining processes, our framework employs GPT-4 for enhanced problem-solving\nand explanation skills. Our experimental backdrop is the smart streetlight\nInternet of Things (IoT) application. Here, agents use sensors, actuators, and\nneural networks to create an energy-efficient lighting system. By integrating\nGPT-4, these agents achieve superior decision-making and adaptability without\nthe need for extensive training. We compare this approach with both traditional\nneuroevolutionary methods and solutions provided by software engineers,\nunderlining the potential of GPT-driven multiagent systems in IoT.\nStructurally, the paper outlines the incorporation of GPT into the agent-driven\nFramework for the Internet of Things (FIoT), introduces our proposed\nGPT-in-the-loop approach, presents comparative results in the IoT context, and\nconcludes with insights and future directions."
                        }
                    }
                ]
            },
            "Tags": {
                "multi_select": [
                    {
                        "name": "iot"
                    },
                    {
                        "name": "the iot"
                    },
                    {
                        "name": "agent driven"
                    },
                    {
                        "name": "things iot"
                    },
                    {
                        "name": "iot context"
                    }
                ]
            },
            "Github": {
                "url": null
            }
        },
        "pdf_path": "D:\\PJLAB\\Agent\\final_project\\papers\\papers_multiagents fra\\2308.10435v1.pdf",
        "arxiv_id": "2308.10435v1"
    },
    {
        "entry": {
            "Name": {
                "title": [
                    {
                        "text": {
                            "content": "A Survey on AgentOps: Categorization, Challenges, and Future Directions"
                        }
                    }
                ]
            },
            "Date": {
                "date": {
                    "start": "2025-08-04"
                }
            },
            "Authors": {
                "rich_text": [
                    {
                        "text": {
                            "content": "Zexin Wang, Jingjing Li, Quan Zhou, Haotian Si, Yuanhao Liu, Jianhui Li, Gaogang Xie, Fei Sun, Dan Pei, Changhua Pei"
                        }
                    }
                ]
            },
            "Abstract": {
                "rich_text": [
                    {
                        "text": {
                            "content": "As the reasoning capabilities of Large Language Models (LLMs) continue to\nadvance, LLM-based agent systems offer advantages in flexibility and\ninterpretability over traditional systems, garnering increasing attention.\nHowever, despite the widespread research interest and industrial application of\nagent systems, these systems, like their traditional counterparts, frequently\nencounter anomalies. These anomalies lead to instability and insecurity,\nhindering their further development. Therefore, a comprehensive and systematic\napproach to the operation and maintenance of agent systems is urgently needed.\nUnfortunately, current research on the operations of agent systems is sparse.\nTo address this gap, we have undertaken a survey on agent system operations\nwith the aim of establishing a clear framework for the field, defining the\nchallenges, and facilitating further development. Specifically, this paper\nbegins by systematically defining anomalies within agent systems, categorizing\nthem into intra-agent anomalies and inter-agent anomalies. Next, we introduce a\nnovel and comprehensive operational framework for agent systems, dubbed Agent\nSystem Operations (AgentOps). We provide detailed definitions and explanations\nof its four key stages: monitoring, anomaly detection, root cause analysis, and\nresolution."
                        }
                    }
                ]
            },
            "Tags": {
                "multi_select": [
                    {
                        "name": "agent anomalies"
                    },
                    {
                        "name": "agent system"
                    },
                    {
                        "name": "operations agentops"
                    },
                    {
                        "name": "agent systems"
                    },
                    {
                        "name": "agent"
                    }
                ]
            },
            "Github": {
                "url": null
            }
        },
        "pdf_path": "D:\\PJLAB\\Agent\\final_project\\papers\\papers_multiagents fra\\2508.02121v1.pdf",
        "arxiv_id": "2508.02121v1"
    }
]