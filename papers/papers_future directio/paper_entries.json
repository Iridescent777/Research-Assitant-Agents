[
    {
        "entry": {
            "Name": {
                "title": [
                    {
                        "text": {
                            "content": "Deep Multiagent Reinforcement Learning: Challenges and Directions"
                        }
                    }
                ]
            },
            "Date": {
                "date": {
                    "start": "2021-06-29"
                }
            },
            "Authors": {
                "rich_text": [
                    {
                        "text": {
                            "content": "Annie Wong, Thomas B\u00e4ck, Anna V. Kononova, Aske Plaat"
                        }
                    }
                ]
            },
            "Abstract": {
                "rich_text": [
                    {
                        "text": {
                            "content": "This paper surveys the field of deep multiagent reinforcement learning. The\ncombination of deep neural networks with reinforcement learning has gained\nincreased traction in recent years and is slowly shifting the focus from\nsingle-agent to multiagent environments. Dealing with multiple agents is\ninherently more complex as (a) the future rewards depend on multiple players'\njoint actions and (b) the computational complexity increases. We present the\nmost common multiagent problem representations and their main challenges, and\nidentify five research areas that address one or more of these challenges:\ncentralised training and decentralised execution, opponent modelling,\ncommunication, efficient coordination, and reward shaping. We find that many\ncomputational studies rely on unrealistic assumptions or are not generalisable\nto other settings; they struggle to overcome the curse of dimensionality or\nnonstationarity. Approaches from psychology and sociology capture promising\nrelevant behaviours, such as communication and coordination, to help agents\nachieve better performance in multiagent settings. We suggest that, for\nmultiagent reinforcement learning to be successful, future research should\naddress these challenges with an interdisciplinary approach to open up new\npossibilities in multiagent reinforcement learning."
                        }
                    }
                ]
            },
            "Tags": {
                "multi_select": [
                    {
                        "name": "multiagent reinforcement"
                    },
                    {
                        "name": "deep multiagent"
                    },
                    {
                        "name": "multiagent"
                    },
                    {
                        "name": "multiple agents"
                    },
                    {
                        "name": "to multiagent"
                    }
                ]
            },
            "Github": {
                "url": null
            }
        },
        "pdf_path": "D:\\PJLAB\\Agent\\final_project\\papers\\papers_future directio\\2106.15691v2.pdf",
        "arxiv_id": "2106.15691v2"
    },
    {
        "entry": {
            "Name": {
                "title": [
                    {
                        "text": {
                            "content": "Self-Adaptive Large Language Model (LLM)-Based Multiagent Systems"
                        }
                    }
                ]
            },
            "Date": {
                "date": {
                    "start": "2023-07-12"
                }
            },
            "Authors": {
                "rich_text": [
                    {
                        "text": {
                            "content": "Nathalia Nascimento, Paulo Alencar, Donald Cowan"
                        }
                    }
                ]
            },
            "Abstract": {
                "rich_text": [
                    {
                        "text": {
                            "content": "In autonomic computing, self-adaptation has been proposed as a fundamental\nparadigm to manage the complexity of multiagent systems (MASs). This achieved\nby extending a system with support to monitor and adapt itself to achieve\nspecific concerns of interest. Communication in these systems is key given that\nin scenarios involving agent interaction, it enhances cooperation and reduces\ncoordination challenges by enabling direct, clear information exchange.\nHowever, improving the expressiveness of the interaction communication with\nMASs is not without challenges. In this sense, the interplay between\nself-adaptive systems and effective communication is crucial for future MAS\nadvancements. In this paper, we propose the integration of large language\nmodels (LLMs) such as GPT-based technologies into multiagent systems. We anchor\nour methodology on the MAPE-K model, which is renowned for its robust support\nin monitoring, analyzing, planning, and executing system adaptations in\nresponse to dynamic environments. We also present a practical illustration of\nthe proposed approach, in which we implement and assess a basic MAS-based\napplication. The approach significantly advances the state-of-the-art of\nself-adaptive systems by proposing a new paradigm for MAS self-adaptation of\nautonomous systems based on LLM capabilities."
                        }
                    }
                ]
            },
            "Tags": {
                "multi_select": [
                    {
                        "name": "autonomic computing"
                    },
                    {
                        "name": "multiagent systems"
                    },
                    {
                        "name": "self adaptive"
                    },
                    {
                        "name": "adaptive systems"
                    },
                    {
                        "name": "agent interaction"
                    }
                ]
            },
            "Github": {
                "url": null
            }
        },
        "pdf_path": "D:\\PJLAB\\Agent\\final_project\\papers\\papers_future directio\\2307.06187v1.pdf",
        "arxiv_id": "2307.06187v1"
    },
    {
        "entry": {
            "Name": {
                "title": [
                    {
                        "text": {
                            "content": "GPT-in-the-Loop: Adaptive Decision-Making for Multiagent Systems"
                        }
                    }
                ]
            },
            "Date": {
                "date": {
                    "start": "2023-08-21"
                }
            },
            "Authors": {
                "rich_text": [
                    {
                        "text": {
                            "content": "Nathalia Nascimento, Paulo Alencar, Donald Cowan"
                        }
                    }
                ]
            },
            "Abstract": {
                "rich_text": [
                    {
                        "text": {
                            "content": "This paper introduces the \"GPT-in-the-loop\" approach, a novel method\ncombining the advanced reasoning capabilities of Large Language Models (LLMs)\nlike Generative Pre-trained Transformers (GPT) with multiagent (MAS) systems.\nVenturing beyond traditional adaptive approaches that generally require long\ntraining processes, our framework employs GPT-4 for enhanced problem-solving\nand explanation skills. Our experimental backdrop is the smart streetlight\nInternet of Things (IoT) application. Here, agents use sensors, actuators, and\nneural networks to create an energy-efficient lighting system. By integrating\nGPT-4, these agents achieve superior decision-making and adaptability without\nthe need for extensive training. We compare this approach with both traditional\nneuroevolutionary methods and solutions provided by software engineers,\nunderlining the potential of GPT-driven multiagent systems in IoT.\nStructurally, the paper outlines the incorporation of GPT into the agent-driven\nFramework for the Internet of Things (FIoT), introduces our proposed\nGPT-in-the-loop approach, presents comparative results in the IoT context, and\nconcludes with insights and future directions."
                        }
                    }
                ]
            },
            "Tags": {
                "multi_select": [
                    {
                        "name": "iot"
                    },
                    {
                        "name": "the iot"
                    },
                    {
                        "name": "agent driven"
                    },
                    {
                        "name": "things iot"
                    },
                    {
                        "name": "iot context"
                    }
                ]
            },
            "Github": {
                "url": null
            }
        },
        "pdf_path": "D:\\PJLAB\\Agent\\final_project\\papers\\papers_future directio\\2308.10435v1.pdf",
        "arxiv_id": "2308.10435v1"
    }
]