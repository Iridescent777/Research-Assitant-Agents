[
    {
        "entry": {
            "Name": {
                "title": [
                    {
                        "text": {
                            "content": "Some Insights into Lifelong Reinforcement Learning Systems"
                        }
                    }
                ]
            },
            "Date": {
                "date": {
                    "start": "2020-01-27"
                }
            },
            "Authors": {
                "rich_text": [
                    {
                        "text": {
                            "content": "Changjian Li"
                        }
                    }
                ]
            },
            "Abstract": {
                "rich_text": [
                    {
                        "text": {
                            "content": "A lifelong reinforcement learning system is a learning system that has the\nability to learn through trail-and-error interaction with the environment over\nits lifetime. In this paper, I give some arguments to show that the traditional\nreinforcement learning paradigm fails to model this type of learning system.\nSome insights into lifelong reinforcement learning are provided, along with a\nsimplistic prototype lifelong reinforcement learning system."
                        }
                    }
                ]
            },
            "Tags": {
                "multi_select": [
                    {
                        "name": "lifelong reinforcement"
                    },
                    {
                        "name": "reinforcement learning"
                    },
                    {
                        "name": "lifelong"
                    },
                    {
                        "name": "traditional reinforcement"
                    },
                    {
                        "name": "reinforcement"
                    }
                ]
            },
            "Github": {
                "url": null
            }
        },
        "pdf_path": "D:/PJLAB/Agent/final_project/papers/papers_reinforcement_learning/2001.09608v1.pdf",
        "arxiv_id": "2001.09608v1"
    },
    {
        "entry": {
            "Name": {
                "title": [
                    {
                        "text": {
                            "content": "Counterexample-Guided Repair of Reinforcement Learning Systems Using Safety Critics"
                        }
                    }
                ]
            },
            "Date": {
                "date": {
                    "start": "2024-05-24"
                }
            },
            "Authors": {
                "rich_text": [
                    {
                        "text": {
                            "content": "David Boetius, Stefan Leue"
                        }
                    }
                ]
            },
            "Abstract": {
                "rich_text": [
                    {
                        "text": {
                            "content": "Naively trained Deep Reinforcement Learning agents may fail to satisfy vital\nsafety constraints. To avoid costly retraining, we may desire to repair a\npreviously trained reinforcement learning agent to obviate unsafe behaviour. We\ndevise a counterexample-guided repair algorithm for repairing reinforcement\nlearning systems leveraging safety critics. The algorithm jointly repairs a\nreinforcement learning agent and a safety critic using gradient-based\nconstrained optimisation."
                        }
                    }
                ]
            },
            "Tags": {
                "multi_select": [
                    {
                        "name": "deep reinforcement"
                    },
                    {
                        "name": "trained reinforcement"
                    },
                    {
                        "name": "repairing reinforcement"
                    },
                    {
                        "name": "learning agent"
                    },
                    {
                        "name": "learning agents"
                    }
                ]
            },
            "Github": {
                "url": null
            }
        },
        "pdf_path": "D:/PJLAB/Agent/final_project/papers/papers_reinforcement_learning/2405.15430v1.pdf",
        "arxiv_id": "2405.15430v1"
    },
    {
        "entry": {
            "Name": {
                "title": [
                    {
                        "text": {
                            "content": "Deep Reinforcement Learning in Computer Vision: A Comprehensive Survey"
                        }
                    }
                ]
            },
            "Date": {
                "date": {
                    "start": "2021-08-25"
                }
            },
            "Authors": {
                "rich_text": [
                    {
                        "text": {
                            "content": "Ngan Le, Vidhiwar Singh Rathour, Kashu Yamazaki, Khoa Luu, Marios Savvides"
                        }
                    }
                ]
            },
            "Abstract": {
                "rich_text": [
                    {
                        "text": {
                            "content": "Deep reinforcement learning augments the reinforcement learning framework and\nutilizes the powerful representation of deep neural networks. Recent works have\ndemonstrated the remarkable successes of deep reinforcement learning in various\ndomains including finance, medicine, healthcare, video games, robotics, and\ncomputer vision. In this work, we provide a detailed review of recent and\nstate-of-the-art research advances of deep reinforcement learning in computer\nvision. We start with comprehending the theories of deep learning,\nreinforcement learning, and deep reinforcement learning. We then propose a\ncategorization of deep reinforcement learning methodologies and discuss their\nadvantages and limitations. In particular, we divide deep reinforcement\nlearning into seven main categories according to their applications in computer\nvision, i.e. (i)landmark localization (ii) object detection; (iii) object\ntracking; (iv) registration on both 2D image and 3D image volumetric data (v)\nimage segmentation; (vi) videos analysis; and (vii) other applications. Each of\nthese categories is further analyzed with reinforcement learning techniques,\nnetwork design, and performance. Moreover, we provide a comprehensive analysis\nof the existing publicly available datasets and examine source code\navailability. Finally, we present some open issues and discuss future research\ndirections on deep reinforcement learning in computer vision"
                        }
                    }
                ]
            },
            "Tags": {
                "multi_select": [
                    {
                        "name": "deep reinforcement"
                    },
                    {
                        "name": "deep neural"
                    },
                    {
                        "name": "learning augments"
                    },
                    {
                        "name": "object tracking"
                    },
                    {
                        "name": "deep learning"
                    }
                ]
            },
            "Github": {
                "url": null
            }
        },
        "pdf_path": "D:/PJLAB/Agent/final_project/papers/papers_reinforcement_learning/2108.11510v1.pdf",
        "arxiv_id": "2108.11510v1"
    },
    {
        "entry": {
            "Name": {
                "title": [
                    {
                        "text": {
                            "content": "Causal Reinforcement Learning: A Survey"
                        }
                    }
                ]
            },
            "Date": {
                "date": {
                    "start": "2023-07-04"
                }
            },
            "Authors": {
                "rich_text": [
                    {
                        "text": {
                            "content": "Zhihong Deng, Jing Jiang, Guodong Long, Chengqi Zhang"
                        }
                    }
                ]
            },
            "Abstract": {
                "rich_text": [
                    {
                        "text": {
                            "content": "Reinforcement learning is an essential paradigm for solving sequential\ndecision problems under uncertainty. Despite many remarkable achievements in\nrecent decades, applying reinforcement learning methods in the real world\nremains challenging. One of the main obstacles is that reinforcement learning\nagents lack a fundamental understanding of the world and must therefore learn\nfrom scratch through numerous trial-and-error interactions. They may also face\nchallenges in providing explanations for their decisions and generalizing the\nacquired knowledge. Causality, however, offers a notable advantage as it can\nformalize knowledge in a systematic manner and leverage invariance for\neffective knowledge transfer. This has led to the emergence of causal\nreinforcement learning, a subfield of reinforcement learning that seeks to\nenhance existing algorithms by incorporating causal relationships into the\nlearning process. In this survey, we comprehensively review the literature on\ncausal reinforcement learning. We first introduce the basic concepts of\ncausality and reinforcement learning, and then explain how causality can\naddress core challenges in non-causal reinforcement learning. We categorize and\nsystematically review existing causal reinforcement learning approaches based\non their target problems and methodologies. Finally, we outline open issues and\nfuture directions in this emerging field."
                        }
                    }
                ]
            },
            "Tags": {
                "multi_select": [
                    {
                        "name": "causal reinforcement"
                    },
                    {
                        "name": "reinforcement learning"
                    },
                    {
                        "name": "knowledge causality"
                    },
                    {
                        "name": "learning agents"
                    },
                    {
                        "name": "reinforcement"
                    }
                ]
            },
            "Github": {
                "url": null
            }
        },
        "pdf_path": "D:/PJLAB/Agent/final_project/papers/papers_reinforcement_learning/2307.01452v2.pdf",
        "arxiv_id": "2307.01452v2"
    },
    {
        "entry": {
            "Name": {
                "title": [
                    {
                        "text": {
                            "content": "Distributed Deep Reinforcement Learning: A Survey and A Multi-Player Multi-Agent Learning Toolbox"
                        }
                    }
                ]
            },
            "Date": {
                "date": {
                    "start": "2022-12-01"
                }
            },
            "Authors": {
                "rich_text": [
                    {
                        "text": {
                            "content": "Qiyue Yin, Tongtong Yu, Shengqi Shen, Jun Yang, Meijing Zhao, Kaiqi Huang, Bin Liang, Liang Wang"
                        }
                    }
                ]
            },
            "Abstract": {
                "rich_text": [
                    {
                        "text": {
                            "content": "With the breakthrough of AlphaGo, deep reinforcement learning becomes a\nrecognized technique for solving sequential decision-making problems. Despite\nits reputation, data inefficiency caused by its trial and error learning\nmechanism makes deep reinforcement learning hard to be practical in a wide\nrange of areas. Plenty of methods have been developed for sample efficient deep\nreinforcement learning, such as environment modeling, experience transfer, and\ndistributed modifications, amongst which, distributed deep reinforcement\nlearning has shown its potential in various applications, such as\nhuman-computer gaming, and intelligent transportation. In this paper, we\nconclude the state of this exciting field, by comparing the classical\ndistributed deep reinforcement learning methods, and studying important\ncomponents to achieve efficient distributed learning, covering single player\nsingle agent distributed deep reinforcement learning to the most complex\nmultiple players multiple agents distributed deep reinforcement learning.\nFurthermore, we review recently released toolboxes that help to realize\ndistributed deep reinforcement learning without many modifications of their\nnon-distributed versions. By analyzing their strengths and weaknesses, a\nmulti-player multi-agent distributed deep reinforcement learning toolbox is\ndeveloped and released, which is further validated on Wargame, a complex\nenvironment, showing usability of the proposed toolbox for multiple players and\nmultiple agents distributed deep reinforcement learning under complex games.\nFinally, we try to point out challenges and future trends, hoping this brief\nreview can provide a guide or a spark for researchers who are interested in\ndistributed deep reinforcement learning."
                        }
                    }
                ]
            },
            "Tags": {
                "multi_select": [
                    {
                        "name": "distributed deep"
                    },
                    {
                        "name": "distributed learning"
                    },
                    {
                        "name": "agent distributed"
                    },
                    {
                        "name": "deep reinforcement"
                    },
                    {
                        "name": "agents distributed"
                    }
                ]
            },
            "Github": {
                "url": null
            }
        },
        "pdf_path": "D:/PJLAB/Agent/final_project/papers/papers_reinforcement_learning/2212.00253v1.pdf",
        "arxiv_id": "2212.00253v1"
    }
]